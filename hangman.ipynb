{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16bc61e5",
   "metadata": {},
   "source": [
    "DATA ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0a856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "HANGMAN CORPUS - EXPLORATORY DATA ANALYSIS (TRAINING ONLY)\n",
      "============================================================\n",
      "\n",
      "1. Loading Data...\n",
      "✓ Corpus size: 50000 words\n",
      "\n",
      "============================================================\n",
      "2. BASIC STATISTICS\n",
      "============================================================\n",
      "\n",
      "Corpus Statistics:\n",
      "             length  unique_letters\n",
      "count  50000.000000    50000.000000\n",
      "mean       9.497460        7.513740\n",
      "std        2.957487        1.972828\n",
      "min        1.000000        1.000000\n",
      "25%        7.000000        6.000000\n",
      "50%        9.000000        8.000000\n",
      "75%       11.000000        9.000000\n",
      "max       24.000000       15.000000\n",
      "\n",
      "============================================================\n",
      "3. WORD LENGTH ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Word Length Distribution (Corpus):\n",
      "length\n",
      "1       46\n",
      "2       84\n",
      "3      388\n",
      "4     1169\n",
      "5     2340\n",
      "6     3755\n",
      "7     5111\n",
      "8     6348\n",
      "9     6808\n",
      "10    6465\n",
      "11    5452\n",
      "12    4292\n",
      "13    3094\n",
      "14    2019\n",
      "15    1226\n",
      "16     698\n",
      "17     375\n",
      "18     174\n",
      "19      88\n",
      "20      40\n",
      "21      16\n",
      "22       8\n",
      "23       3\n",
      "24       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Most common word length: 9 letters\n",
      "Average word length: 9.50 letters\n",
      "Median word length: 9 letters\n",
      "Shortest word: 1 letters\n",
      "Longest word: 24 letters\n",
      "\n",
      "============================================================\n",
      "4. LETTER FREQUENCY ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Top 15 Most Frequent Letters in Corpus:\n",
      "  e: 49,224 (10.37%)\n",
      "  a: 42,110 (8.87%)\n",
      "  i: 42,068 (8.86%)\n",
      "  o: 35,829 (7.54%)\n",
      "  r: 33,619 (7.08%)\n",
      "  n: 33,314 (7.02%)\n",
      "  t: 32,191 (6.78%)\n",
      "  s: 29,044 (6.12%)\n",
      "  l: 27,406 (5.77%)\n",
      "  c: 21,718 (4.57%)\n",
      "  u: 18,397 (3.87%)\n",
      "  p: 16,426 (3.46%)\n",
      "  m: 14,670 (3.09%)\n",
      "  d: 14,324 (3.02%)\n",
      "  h: 13,643 (2.87%)\n",
      "\n",
      "Least Common Letters in Corpus:\n",
      "  z: 1,923 (0.40%)\n",
      "  x: 1,532 (0.32%)\n",
      "  q: 915 (0.19%)\n",
      "  j: 849 (0.18%)\n",
      "   : 21 (0.00%)\n",
      "\n",
      "============================================================\n",
      "5. POSITION-BASED LETTER ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Top 10 Starting Letters:\n",
      "  p: 5198 words (10.40%)\n",
      "  s: 5184 words (10.37%)\n",
      "  c: 4130 words (8.26%)\n",
      "  a: 3599 words (7.20%)\n",
      "  u: 3400 words (6.80%)\n",
      "  t: 2701 words (5.40%)\n",
      "  m: 2664 words (5.33%)\n",
      "  b: 2339 words (4.68%)\n",
      "  d: 2324 words (4.65%)\n",
      "  r: 2051 words (4.10%)\n",
      "\n",
      "Top 10 Ending Letters:\n",
      "  e: 9307 words (18.61%)\n",
      "  y: 5755 words (11.51%)\n",
      "  s: 5402 words (10.80%)\n",
      "  n: 4257 words (8.51%)\n",
      "  d: 3286 words (6.57%)\n",
      "  r: 3282 words (6.56%)\n",
      "  t: 3182 words (6.36%)\n",
      "  l: 3146 words (6.29%)\n",
      "  a: 2691 words (5.38%)\n",
      "  c: 2354 words (4.71%)\n",
      "\n",
      "============================================================\n",
      "6. UNIQUE LETTERS PER WORD\n",
      "============================================================\n",
      "\n",
      "Average unique letters per word: 7.51\n",
      "Median unique letters per word: 8\n",
      "\n",
      "Distribution of Unique Letters:\n",
      "  1 unique letters: 47 words (0.09%)\n",
      "  2 unique letters: 131 words (0.26%)\n",
      "  3 unique letters: 747 words (1.49%)\n",
      "  4 unique letters: 2207 words (4.41%)\n",
      "  5 unique letters: 4669 words (9.34%)\n",
      "  6 unique letters: 7388 words (14.78%)\n",
      "  7 unique letters: 9658 words (19.32%)\n",
      "  8 unique letters: 9599 words (19.20%)\n",
      "  9 unique letters: 7691 words (15.38%)\n",
      "  10 unique letters: 4716 words (9.43%)\n",
      "  11 unique letters: 2163 words (4.33%)\n",
      "  12 unique letters: 770 words (1.54%)\n",
      "  13 unique letters: 174 words (0.35%)\n",
      "  14 unique letters: 36 words (0.07%)\n",
      "  15 unique letters: 4 words (0.01%)\n",
      "\n",
      "============================================================\n",
      "7. VOWEL vs CONSONANT ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Average vowels per word: 3.75\n",
      "Average consonants per word: 5.74\n",
      "Average vowel ratio: 39.41%\n",
      "\n",
      "Vowel Count Distribution:\n",
      "  0 vowels: 190 words (0.38%)\n",
      "  1 vowels: 1844 words (3.69%)\n",
      "  2 vowels: 7800 words (15.60%)\n",
      "  3 vowels: 12940 words (25.88%)\n",
      "  4 vowels: 12858 words (25.72%)\n",
      "  5 vowels: 8559 words (17.12%)\n",
      "  6 vowels: 4057 words (8.11%)\n",
      "  7 vowels: 1318 words (2.64%)\n",
      "  8 vowels: 354 words (0.71%)\n",
      "  9 vowels: 64 words (0.13%)\n",
      "  10 vowels: 15 words (0.03%)\n",
      "  11 vowels: 1 words (0.00%)\n",
      "\n",
      "============================================================\n",
      "8. BIGRAM ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Top 20 Most Common Bigrams:\n",
      "  'er': 8829 occurrences (2.08%)\n",
      "  'in': 7127 occurrences (1.68%)\n",
      "  'ti': 6631 occurrences (1.56%)\n",
      "  'te': 6139 occurrences (1.44%)\n",
      "  'on': 6135 occurrences (1.44%)\n",
      "  'al': 5904 occurrences (1.39%)\n",
      "  'an': 5858 occurrences (1.38%)\n",
      "  'at': 5799 occurrences (1.36%)\n",
      "  'ic': 5415 occurrences (1.27%)\n",
      "  'en': 5215 occurrences (1.23%)\n",
      "  'is': 5020 occurrences (1.18%)\n",
      "  'ra': 4969 occurrences (1.17%)\n",
      "  're': 4913 occurrences (1.16%)\n",
      "  'le': 4874 occurrences (1.15%)\n",
      "  'ri': 4861 occurrences (1.14%)\n",
      "  'st': 4715 occurrences (1.11%)\n",
      "  'ro': 4686 occurrences (1.10%)\n",
      "  'ne': 4511 occurrences (1.06%)\n",
      "  'ar': 4432 occurrences (1.04%)\n",
      "  'li': 4374 occurrences (1.03%)\n",
      "\n",
      "============================================================\n",
      "9. REPEATED LETTERS ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Words with repeated letters: 10620 (21.24%)\n",
      "\n",
      "Most Common Repeated Letters:\n",
      "  ss: 2941 occurrences\n",
      "  ll: 2390 occurrences\n",
      "  oo: 960 occurrences\n",
      "  ee: 804 occurrences\n",
      "  rr: 759 occurrences\n",
      "  tt: 718 occurrences\n",
      "  nn: 534 occurrences\n",
      "  pp: 416 occurrences\n",
      "  mm: 389 occurrences\n",
      "  ff: 338 occurrences\n",
      "\n",
      "============================================================\n",
      "10. WORD COMPLEXITY ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Words with ALL unique letters (no repeats):\n",
      "Count: 9076 words (18.15%)\n",
      "Examples: ['unbed', 'kulang', 'hour', 'chandu', 'nib', 'upbid', 'mdel', 'anhemolytic', 'tunable', 'subcategory']\n",
      "\n",
      "Words with HIGH letter repetition (uniqueness < 0.5):\n",
      "Count: 109 words (0.22%)\n",
      "Examples: ['inefficience', 'stresslessness', 'poroporo', 'antistatist', 'spinelessness', 'fiddledeedee', 'assessee', 'eisegesis', 'colocolic', 'kivikivi']\n",
      "\n",
      "============================================================\n",
      "11. SAMPLE WORDS BY LENGTH\n",
      "============================================================\n",
      "\n",
      "Length 1: v, d, b, m, o\n",
      "\n",
      "Length 2: pf, wp, ux, hq, ze\n",
      "\n",
      "Length 3: nib, bnn, ola, dia, tan\n",
      "\n",
      "Length 4: hour, mdel, trxe, tama, dike\n",
      "\n",
      "Length 5: unbed, upbid, linge, birma, brock\n",
      "\n",
      "Length 6: asmack, higgle, kulang, chandu, pursue\n",
      "\n",
      "Length 7: tunable, bajardo, emprise, frogbit, justina\n",
      "\n",
      "Length 8: selamlik, unsealed, wanworth, sonorous, reborrow\n",
      "\n",
      "Length 9: hypotypic, cacomelia, thicklips, yellowcup, rancorous\n",
      "\n",
      "Length 10: luciferase, propodiale, overprizer, juratorial, fusionless\n",
      "\n",
      "============================================================\n",
      "13. KEY INSIGHTS FOR HANGMAN STRATEGY (TRAINING SET ONLY)\n",
      "============================================================\n",
      "\n",
      "✓ MOST VALUABLE FIRST GUESSES (by frequency):\n",
      "  Recommended order: e, a, i, o, r, n, t, s, l, c\n",
      "\n",
      "✓ POSITION STRATEGY:\n",
      "  - Best starting letter guesses: p, s, c, a, u\n",
      "  - Best ending letter guesses: e, y, s, n, d\n",
      "\n",
      "✓ COMMON PATTERNS:\n",
      "  - Most common bigrams: er, in, ti, te, on\n",
      "  - Most common repeated letters: s, l, o, e, r\n",
      "\n",
      "✓ WORD LENGTH STRATEGY:\n",
      "  Most common word lengths:\n",
      "    - 9 letters: 6808 words (13.62%)\n",
      "    - 10 letters: 6465 words (12.93%)\n",
      "    - 8 letters: 6348 words (12.70%)\n",
      "\n",
      "============================================================\n",
      "EDA COMPLETE! (TEST DATA NEVER TOUCHED)\n",
      "============================================================\n",
      "\n",
      "✓ Training summary saved to: corpus_eda_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"HANGMAN CORPUS - EXPLORATORY DATA ANALYSIS (TRAINING ONLY)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load only the corpus (training set)\n",
    "print(\"\\n1. Loading Data...\")\n",
    "with open('Data/Data/corpus.txt', 'r', encoding='utf-8') as f:\n",
    "    corpus_words = [word.strip().lower() for word in f.readlines() if word.strip()]\n",
    "\n",
    "print(f\"✓ Corpus size: {len(corpus_words)} words\")\n",
    "\n",
    "# DataFrame for corpus\n",
    "corpus_df = pd.DataFrame({\n",
    "    'word': corpus_words,\n",
    "    'length': [len(word) for word in corpus_words],\n",
    "    'unique_letters': [len(set(word)) for word in corpus_words]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. BASIC STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nCorpus Statistics:\")\n",
    "print(corpus_df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3. WORD LENGTH ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "length_dist = corpus_df['length'].value_counts().sort_index()\n",
    "print(\"\\nWord Length Distribution (Corpus):\")\n",
    "print(length_dist)\n",
    "\n",
    "print(f\"\\nMost common word length: {corpus_df['length'].mode()[0]} letters\")\n",
    "print(f\"Average word length: {corpus_df['length'].mean():.2f} letters\")\n",
    "print(f\"Median word length: {corpus_df['length'].median():.0f} letters\")\n",
    "print(f\"Shortest word: {corpus_df['length'].min()} letters\")\n",
    "print(f\"Longest word: {corpus_df['length'].max()} letters\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4. LETTER FREQUENCY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_letters = ''.join(corpus_words)\n",
    "letter_freq = Counter(all_letters)\n",
    "total_letters = sum(letter_freq.values())\n",
    "\n",
    "print(\"\\nTop 15 Most Frequent Letters in Corpus:\")\n",
    "for letter, count in letter_freq.most_common(15):\n",
    "    percentage = (count / total_letters) * 100\n",
    "    print(f\"  {letter}: {count:,} ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\nLeast Common Letters in Corpus:\")\n",
    "for letter, count in letter_freq.most_common()[-5:]:\n",
    "    percentage = (count / total_letters) * 100\n",
    "    print(f\"  {letter}: {count:,} ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5. POSITION-BASED LETTER ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "starting_letters = Counter([word[0] for word in corpus_words])\n",
    "print(\"\\nTop 10 Starting Letters:\")\n",
    "for letter, count in starting_letters.most_common(10):\n",
    "    percentage = (count / len(corpus_words)) * 100\n",
    "    print(f\"  {letter}: {count} words ({percentage:.2f}%)\")\n",
    "\n",
    "ending_letters = Counter([word[-1] for word in corpus_words])\n",
    "print(\"\\nTop 10 Ending Letters:\")\n",
    "for letter, count in ending_letters.most_common(10):\n",
    "    percentage = (count / len(corpus_words)) * 100\n",
    "    print(f\"  {letter}: {count} words ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"6. UNIQUE LETTERS PER WORD\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nAverage unique letters per word: {corpus_df['unique_letters'].mean():.2f}\")\n",
    "print(f\"Median unique letters per word: {corpus_df['unique_letters'].median():.0f}\")\n",
    "\n",
    "print(\"\\nDistribution of Unique Letters:\")\n",
    "unique_dist = corpus_df['unique_letters'].value_counts().sort_index()\n",
    "for num, count in unique_dist.items():\n",
    "    percentage = (count / len(corpus_words)) * 100\n",
    "    print(f\"  {num} unique letters: {count} words ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"7. VOWEL vs CONSONANT ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vowels = set('aeiou')\n",
    "consonants = set('bcdfghjklmnpqrstvwxyz')\n",
    "\n",
    "def count_vowels(word):\n",
    "    return sum(1 for c in word if c in vowels)\n",
    "\n",
    "def count_consonants(word):\n",
    "    return sum(1 for c in word if c in consonants)\n",
    "\n",
    "corpus_df['vowels'] = corpus_df['word'].apply(count_vowels)\n",
    "corpus_df['consonants'] = corpus_df['word'].apply(count_consonants)\n",
    "corpus_df['vowel_ratio'] = corpus_df['vowels'] / corpus_df['length']\n",
    "\n",
    "print(f\"\\nAverage vowels per word: {corpus_df['vowels'].mean():.2f}\")\n",
    "print(f\"Average consonants per word: {corpus_df['consonants'].mean():.2f}\")\n",
    "print(f\"Average vowel ratio: {corpus_df['vowel_ratio'].mean():.2%}\")\n",
    "\n",
    "print(\"\\nVowel Count Distribution:\")\n",
    "vowel_dist = corpus_df['vowels'].value_counts().sort_index()\n",
    "for num, count in vowel_dist.items():\n",
    "    percentage = (count / len(corpus_words)) * 100\n",
    "    print(f\"  {num} vowels: {count} words ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"8. BIGRAM ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "bigrams = []\n",
    "for word in corpus_words:\n",
    "    for i in range(len(word) - 1):\n",
    "        bigrams.append(word[i:i+2])\n",
    "\n",
    "bigram_freq = Counter(bigrams)\n",
    "print(\"\\nTop 20 Most Common Bigrams:\")\n",
    "for bigram, count in bigram_freq.most_common(20):\n",
    "    percentage = (count / len(bigrams)) * 100\n",
    "    print(f\"  '{bigram}': {count} occurrences ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"9. REPEATED LETTERS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def has_repeated_letters(word):\n",
    "    for i in range(len(word) - 1):\n",
    "        if word[i] == word[i+1]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "words_with_repeats = sum(1 for word in corpus_words if has_repeated_letters(word))\n",
    "print(f\"\\nWords with repeated letters: {words_with_repeats} ({words_with_repeats/len(corpus_words)*100:.2f}%)\")\n",
    "\n",
    "repeated_pairs = []\n",
    "for word in corpus_words:\n",
    "    for i in range(len(word) - 1):\n",
    "        if word[i] == word[i+1]:\n",
    "            repeated_pairs.append(word[i])\n",
    "\n",
    "repeated_freq = Counter(repeated_pairs)\n",
    "print(\"\\nMost Common Repeated Letters:\")\n",
    "for letter, count in repeated_freq.most_common(10):\n",
    "    print(f\"  {letter}{letter}: {count} occurrences\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"10. WORD COMPLEXITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "corpus_df['uniqueness_ratio'] = corpus_df['unique_letters'] / corpus_df['length']\n",
    "\n",
    "print(\"\\nWords with ALL unique letters (no repeats):\")\n",
    "all_unique = corpus_df[corpus_df['uniqueness_ratio'] == 1.0]\n",
    "print(f\"Count: {len(all_unique)} words ({len(all_unique)/len(corpus_words)*100:.2f}%)\")\n",
    "print(f\"Examples: {all_unique['word'].head(10).tolist()}\")\n",
    "\n",
    "print(\"\\nWords with HIGH letter repetition (uniqueness < 0.5):\")\n",
    "high_repeat = corpus_df[corpus_df['uniqueness_ratio'] < 0.5]\n",
    "print(f\"Count: {len(high_repeat)} words ({len(high_repeat)/len(corpus_words)*100:.2f}%)\")\n",
    "print(f\"Examples: {high_repeat['word'].head(10).tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"11. SAMPLE WORDS BY LENGTH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for length in sorted(corpus_df['length'].unique())[:10]:\n",
    "    sample_words = corpus_df[corpus_df['length'] == length]['word'].head(5).tolist()\n",
    "    print(f\"\\nLength {length}: {', '.join(sample_words)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"13. KEY INSIGHTS FOR HANGMAN STRATEGY (TRAINING SET ONLY)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n✓ MOST VALUABLE FIRST GUESSES (by frequency):\")\n",
    "top_letters = [letter for letter, _ in letter_freq.most_common(10)]\n",
    "print(f\"  Recommended order: {', '.join(top_letters)}\")\n",
    "\n",
    "print(\"\\n✓ POSITION STRATEGY:\")\n",
    "print(f\"  - Best starting letter guesses: {', '.join([l for l, _ in starting_letters.most_common(5)])}\")\n",
    "print(f\"  - Best ending letter guesses: {', '.join([l for l, _ in ending_letters.most_common(5)])}\")\n",
    "\n",
    "print(\"\\n✓ COMMON PATTERNS:\")\n",
    "print(f\"  - Most common bigrams: {', '.join([b for b, _ in bigram_freq.most_common(5)])}\")\n",
    "print(f\"  - Most common repeated letters: {', '.join([l for l, _ in repeated_freq.most_common(5)])}\")\n",
    "\n",
    "print(\"\\n✓ WORD LENGTH STRATEGY:\")\n",
    "most_common_lengths = corpus_df['length'].value_counts().head(3)\n",
    "print(\"  Most common word lengths:\")\n",
    "for length, count in most_common_lengths.items():\n",
    "    print(f\"    - {length} letters: {count} words ({count/len(corpus_words)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EDA COMPLETE! (TEST DATA NEVER TOUCHED)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Optionally save only corpus/training summary to CSV\n",
    "summary_df = pd.DataFrame({\n",
    "    'Metric': ['Total Words', 'Unique Words', 'Avg Length', 'Most Common Length', \n",
    "               'Total Letters', 'Unique Letters Used'],\n",
    "    'Corpus': [len(corpus_words), len(set(corpus_words)), \n",
    "               f\"{corpus_df['length'].mean():.2f}\", corpus_df['length'].mode()[0],\n",
    "               total_letters, len(letter_freq)]\n",
    "})\n",
    "summary_df.to_csv('corpus_eda_summary.csv', index=False)\n",
    "print(\"\\n✓ Training summary saved to: corpus_eda_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af33ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== COMPLETE HANGMAN SOLVER ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "# ==================== STATISTICAL HMM ====================\n",
    "class StatisticalHangmanHMM:\n",
    "    def __init__(self):\n",
    "        self.words = []\n",
    "        self.global_freq = Counter()\n",
    "        self.length_freq = {}\n",
    "        self.first_letter_freq = Counter()\n",
    "        self.second_letter_freq = Counter()\n",
    "        self.last_letter_freq = Counter()\n",
    "        self.second_last_freq = Counter()\n",
    "        self.position_bins = {i: Counter() for i in range(10)}\n",
    "        self.after_letter = defaultdict(Counter)\n",
    "        self.before_letter = defaultdict(Counter)\n",
    "        self.letter_pairs = Counter()\n",
    "        self.vowels = set('aeiou')\n",
    "        self.consonants = set('bcdfghjklmnpqrstvwxyz')\n",
    "        self.vowel_positions = defaultdict(Counter)\n",
    "        self.common_order = ['e', 'a', 'i', 'o', 'r', 'n', 't', 's', 'l', 'c', 'u', 'd', 'p', 'm', 'h']\n",
    "        \n",
    "    def train(self, corpus_path):\n",
    "        print(\"Training Statistical HMM...\")\n",
    "        with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "            self.words = [word.strip().lower() for word in f.readlines() if word.strip()]\n",
    "        \n",
    "        print(f\"Analyzing {len(self.words)} words...\")\n",
    "        \n",
    "        for word in self.words:\n",
    "            wlen = len(word)\n",
    "            \n",
    "            # Global frequency\n",
    "            for char in word:\n",
    "                self.global_freq[char] += 1\n",
    "            \n",
    "            # Length-specific frequency\n",
    "            if wlen not in self.length_freq:\n",
    "                self.length_freq[wlen] = Counter()\n",
    "            for char in word:\n",
    "                self.length_freq[wlen][char] += 1\n",
    "            \n",
    "            # Fixed positions\n",
    "            if wlen >= 1:\n",
    "                self.first_letter_freq[word[0]] += 1\n",
    "            if wlen >= 2:\n",
    "                self.second_letter_freq[word[1]] += 1\n",
    "                self.last_letter_freq[word[-1]] += 1\n",
    "            if wlen >= 3:\n",
    "                self.second_last_freq[word[-2]] += 1\n",
    "            \n",
    "            # Relative positions\n",
    "            for i, char in enumerate(word):\n",
    "                rel_pos = int((i / wlen) * 10) if wlen > 1 else 0\n",
    "                rel_pos = min(rel_pos, 9)\n",
    "                self.position_bins[rel_pos][char] += 1\n",
    "            \n",
    "            # Conditional probabilities\n",
    "            for i in range(len(word) - 1):\n",
    "                curr, nxt = word[i], word[i+1]\n",
    "                self.after_letter[curr][nxt] += 1\n",
    "                self.before_letter[nxt][curr] += 1\n",
    "                self.letter_pairs[(curr, nxt)] += 1\n",
    "            \n",
    "            # Vowel positions\n",
    "            for i, char in enumerate(word):\n",
    "                if char in self.vowels:\n",
    "                    rel_pos = int((i / wlen) * 10) if wlen > 1 else 0\n",
    "                    rel_pos = min(rel_pos, 9)\n",
    "                    self.vowel_positions[rel_pos][char] += 1\n",
    "        \n",
    "        # Normalize everything\n",
    "        self._normalize()\n",
    "        print(\"HMM training complete!\")\n",
    "    \n",
    "    def _normalize(self):\n",
    "        total = sum(self.global_freq.values())\n",
    "        self.global_freq = {k: v/total for k, v in self.global_freq.items()}\n",
    "        \n",
    "        for length in self.length_freq:\n",
    "            total = sum(self.length_freq[length].values())\n",
    "            self.length_freq[length] = {k: v/total for k, v in self.length_freq[length].items()}\n",
    "        \n",
    "        for counter in [self.first_letter_freq, self.second_letter_freq, \n",
    "                       self.last_letter_freq, self.second_last_freq]:\n",
    "            total = sum(counter.values())\n",
    "            if total > 0:\n",
    "                for k in list(counter.keys()):\n",
    "                    counter[k] = counter[k] / total\n",
    "        \n",
    "        for i in range(10):\n",
    "            total = sum(self.position_bins[i].values())\n",
    "            if total > 0:\n",
    "                self.position_bins[i] = {k: v/total for k, v in self.position_bins[i].items()}\n",
    "        \n",
    "        for letter in self.after_letter:\n",
    "            total = sum(self.after_letter[letter].values())\n",
    "            if total > 0:\n",
    "                self.after_letter[letter] = {k: v/total for k, v in self.after_letter[letter].items()}\n",
    "        \n",
    "        for letter in self.before_letter:\n",
    "            total = sum(self.before_letter[letter].values())\n",
    "            if total > 0:\n",
    "                self.before_letter[letter] = {k: v/total for k, v in self.before_letter[letter].items()}\n",
    "        \n",
    "        for pos in self.vowel_positions:\n",
    "            total = sum(self.vowel_positions[pos].values())\n",
    "            if total > 0:\n",
    "                self.vowel_positions[pos] = {k: v/total for k, v in self.vowel_positions[pos].items()}\n",
    "    \n",
    "    def predict_letter_probabilities(self, pattern, guessed_letters, lives_remaining):\n",
    "        wlen = len(pattern)\n",
    "        scores = Counter()\n",
    "        \n",
    "        weights = {\n",
    "            'global': 0.20,\n",
    "            'length': 0.25,\n",
    "            'position': 0.25,\n",
    "            'context': 0.30\n",
    "        }\n",
    "        \n",
    "        # 1. Global frequency baseline\n",
    "        for letter in self.common_order:\n",
    "            if letter not in guessed_letters:\n",
    "                freq = self.global_freq.get(letter, 0.001)\n",
    "                scores[letter] += weights['global'] * freq\n",
    "        \n",
    "        # 2. Length-specific frequency\n",
    "        if wlen in self.length_freq:\n",
    "            for letter, prob in self.length_freq[wlen].items():\n",
    "                if letter not in guessed_letters:\n",
    "                    scores[letter] += weights['length'] * prob\n",
    "        \n",
    "        # 3. Position-based predictions\n",
    "        blank_positions = [i for i, c in enumerate(pattern) if c == '_']\n",
    "        \n",
    "        for pos in blank_positions:\n",
    "            if pos == 0:\n",
    "                for letter, prob in self.first_letter_freq.items():\n",
    "                    if letter not in guessed_letters:\n",
    "                        scores[letter] += weights['position'] * prob / len(blank_positions)\n",
    "            elif pos == 1 and wlen >= 2:\n",
    "                for letter, prob in self.second_letter_freq.items():\n",
    "                    if letter not in guessed_letters:\n",
    "                        scores[letter] += weights['position'] * prob / len(blank_positions)\n",
    "            elif pos == wlen - 1:\n",
    "                for letter, prob in self.last_letter_freq.items():\n",
    "                    if letter not in guessed_letters:\n",
    "                        scores[letter] += weights['position'] * prob / len(blank_positions)\n",
    "            elif pos == wlen - 2 and wlen >= 3:\n",
    "                for letter, prob in self.second_last_freq.items():\n",
    "                    if letter not in guessed_letters:\n",
    "                        scores[letter] += weights['position'] * prob / len(blank_positions)\n",
    "            \n",
    "            rel_pos = int((pos / wlen) * 10) if wlen > 1 else 0\n",
    "            rel_pos = min(rel_pos, 9)\n",
    "            for letter, prob in self.position_bins[rel_pos].items():\n",
    "                if letter not in guessed_letters:\n",
    "                    scores[letter] += weights['position'] * prob * 0.5 / len(blank_positions)\n",
    "        \n",
    "        # 4. Context-based\n",
    "        for i, char in enumerate(pattern):\n",
    "            if char != '_':\n",
    "                if i > 0 and pattern[i-1] == '_':\n",
    "                    for prev_letter, prob in self.before_letter[char].items():\n",
    "                        if prev_letter not in guessed_letters:\n",
    "                            scores[prev_letter] += weights['context'] * prob\n",
    "                \n",
    "                if i < wlen - 1 and pattern[i+1] == '_':\n",
    "                    for next_letter, prob in self.after_letter[char].items():\n",
    "                        if next_letter not in guessed_letters:\n",
    "                            scores[next_letter] += weights['context'] * prob\n",
    "        \n",
    "        # 5. Vowel pattern heuristic\n",
    "        revealed_letters = [c for c in pattern if c != '_']\n",
    "        vowel_count = sum(1 for c in revealed_letters if c in self.vowels)\n",
    "        consonant_count = len(revealed_letters) - vowel_count\n",
    "        \n",
    "        if consonant_count > vowel_count + 2:\n",
    "            for letter in self.vowels:\n",
    "                if letter not in guessed_letters:\n",
    "                    scores[letter] *= 1.5\n",
    "        \n",
    "        if vowel_count > consonant_count:\n",
    "            for letter in self.consonants:\n",
    "                if letter not in guessed_letters:\n",
    "                    scores[letter] *= 1.2\n",
    "        \n",
    "        total = sum(scores.values())\n",
    "        if total > 0:\n",
    "            scores = {k: v/total for k, v in scores.items()}\n",
    "        else:\n",
    "            scores = {letter: 1.0/(i+1) for i, letter in enumerate(self.common_order) \n",
    "                     if letter not in guessed_letters}\n",
    "            total = sum(scores.values())\n",
    "            scores = {k: v/total for k, v in scores.items()}\n",
    "        \n",
    "        return dict(scores)\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_model(filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f599ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== RL AGENT ====================\n",
    "class GeneralStrategyRLAgent:\n",
    "    def __init__(self, hmm_model):\n",
    "        self.hmm = hmm_model\n",
    "        self.strategy_weights = {}\n",
    "        self.letter_bias = np.zeros(26)\n",
    "        self.learning_rate = 0.005\n",
    "        self.epsilon = 0.2\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.05\n",
    "        self.gamma = 0.9\n",
    "\n",
    "    def get_state_features(self, pattern, guessed_letters, lives_remaining):\n",
    "        wlen = len(pattern)\n",
    "        revealed = sum(1 for c in pattern if c != '_')\n",
    "        progress = revealed / wlen if wlen > 0 else 0\n",
    "        length_bucket = min(wlen // 3, 4)\n",
    "        progress_bucket = int(progress * 4)\n",
    "        lives_bucket = min(lives_remaining // 2, 2)\n",
    "        return (length_bucket, progress_bucket, lives_bucket)\n",
    "\n",
    "    def get_strategy_weights(self, state):\n",
    "        if state not in self.strategy_weights:\n",
    "            self.strategy_weights[state] = np.array([0.20, 0.25, 0.25, 0.30])\n",
    "        return self.strategy_weights[state]\n",
    "\n",
    "    def select_action(self, pattern, guessed_letters, hmm_probs, lives_remaining, epsilon=None):\n",
    "        if epsilon is None:\n",
    "            epsilon = self.epsilon\n",
    "        available_letters = [chr(ord('a') + i) for i in range(26) if chr(ord('a') + i) not in guessed_letters]\n",
    "        if not available_letters:\n",
    "            return 'e'\n",
    "\n",
    "        adjusted_probs = {}\n",
    "        for letter in available_letters:\n",
    "            hmm_prob = hmm_probs.get(letter, 0.001)\n",
    "            letter_idx = ord(letter) - ord('a')\n",
    "            bias = self.letter_bias[letter_idx]\n",
    "            adjusted_prob = hmm_prob * (1.0 + bias * 0.2)\n",
    "            adjusted_probs[letter] = max(adjusted_prob, 0.001)\n",
    "        \n",
    "        total = sum(adjusted_probs.values())\n",
    "        for letter in adjusted_probs:\n",
    "            adjusted_probs[letter] /= total\n",
    "\n",
    "        if np.random.random() < epsilon:\n",
    "            letters = list(adjusted_probs.keys())\n",
    "            probs = np.array([adjusted_probs[l] for l in letters])\n",
    "            probs = probs / probs.sum()\n",
    "            letter = np.random.choice(letters, p=probs)\n",
    "        else:\n",
    "            letter = max(adjusted_probs.items(), key=lambda x:x[1])[0]\n",
    "        return letter\n",
    "\n",
    "    def update(self, state_features, letter, reward, next_state_features, done):\n",
    "        letter_idx = ord(letter) - ord('a')\n",
    "        if reward > 0:\n",
    "            self.letter_bias[letter_idx] += self.learning_rate * 0.5\n",
    "        elif reward < 0:\n",
    "            self.letter_bias[letter_idx] -= self.learning_rate * 0.3\n",
    "        self.letter_bias = np.clip(self.letter_bias, -2.0, 2.0)\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        data = {\n",
    "            'letter_bias': self.letter_bias,\n",
    "            'strategy_weights': self.strategy_weights,\n",
    "            'epsilon': self.epsilon,\n",
    "        }\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"RL Agent saved to {filepath}\")\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        self.letter_bias = data['letter_bias']\n",
    "        self.strategy_weights = data['strategy_weights']\n",
    "        self.epsilon = data['epsilon']\n",
    "        print(f\"RL Agent loaded from {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255e5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== ENVIRONMENT ====================\n",
    "class HangmanEnvironment:\n",
    "    def __init__(self, word, hmm_model):\n",
    "        self.word = word.lower()\n",
    "        self.hmm = hmm_model\n",
    "        self.guessed_letters = set()\n",
    "        self.lives_remaining = 6\n",
    "        self.current_pattern = ''.join('_' for _ in self.word)\n",
    "        self.gameover = False\n",
    "        self.won = False\n",
    "\n",
    "    def get_state_features(self):\n",
    "        wlen = len(self.current_pattern)\n",
    "        revealed = sum(1 for c in self.current_pattern if c != '_')\n",
    "        progress = revealed / wlen if wlen > 0 else 0\n",
    "        length_bucket = min(wlen // 3, 4)\n",
    "        progress_bucket = int(progress * 4)\n",
    "        lives_bucket = min(self.lives_remaining // 2, 2)\n",
    "        return (length_bucket, progress_bucket, lives_bucket)\n",
    "\n",
    "    def step(self, letter):\n",
    "        if self.gameover:\n",
    "            return 0, True, {'error': 'Game already over'}\n",
    "        if letter in self.guessed_letters:\n",
    "            return -10.0, False, {'type': 'repeated', 'correct': False}\n",
    "        self.guessed_letters.add(letter)\n",
    "        if letter in self.word:\n",
    "            self.current_pattern = ''.join(\n",
    "                c if c in self.guessed_letters else '_' for c in self.word\n",
    "            )\n",
    "            if '_' not in self.current_pattern:\n",
    "                self.gameover = True\n",
    "                self.won = True\n",
    "                return 100.0, True, {'type': 'win', 'correct': True}\n",
    "            else:\n",
    "                num_revealed = self.current_pattern.count(letter)\n",
    "                return 10.0 * num_revealed + 2.0, False, {'type': 'correct', 'correct': True}\n",
    "        else:\n",
    "            self.lives_remaining -= 1\n",
    "            if self.lives_remaining == 0:\n",
    "                self.gameover = True\n",
    "                self.won = False\n",
    "                return -100.0, True, {'type': 'lose', 'correct': False}\n",
    "            else:\n",
    "                penalty = -10.0 - (6 - self.lives_remaining) * 3.0\n",
    "                return penalty, False, {'type': 'wrong', 'correct': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f681bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== RL TRAINER ====================\n",
    "class RLTrainer:\n",
    "    def __init__(self, hmm_model, words_list):\n",
    "        self.hmm = hmm_model\n",
    "        self.words = words_list\n",
    "        self.agent = GeneralStrategyRLAgent(hmm_model)\n",
    "\n",
    "    def train(self, num_episodes=2000, words_per_episode=100):\n",
    "        print(\"=\"*80)\n",
    "        print(f\"RL TRAINING {num_episodes} EPISODES\")\n",
    "        print(f\"Words per episode: {words_per_episode}\")\n",
    "        print(f\"Total training games: {num_episodes * words_per_episode:,}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Track performance metrics\n",
    "        episode_metrics = []\n",
    "        \n",
    "        for episode in range(num_episodes):\n",
    "            episode_wins = 0\n",
    "            episode_games = 0\n",
    "            episode_reward = 0\n",
    "            episode_correct_guesses = 0\n",
    "            episode_wrong_guesses = 0\n",
    "            \n",
    "            sampled_words = random.sample(self.words, min(words_per_episode, len(self.words)))\n",
    "            for word in sampled_words:\n",
    "                env = HangmanEnvironment(word, self.hmm)\n",
    "                done = False\n",
    "                while not done:\n",
    "                    state = env.get_state_features()\n",
    "                    hmm_probs = self.hmm.predict_letter_probabilities(\n",
    "                        env.current_pattern,\n",
    "                        env.guessed_letters,\n",
    "                        env.lives_remaining,\n",
    "                    )\n",
    "                    letter = self.agent.select_action(\n",
    "                        env.current_pattern,\n",
    "                        env.guessed_letters,\n",
    "                        hmm_probs,\n",
    "                        env.lives_remaining\n",
    "                    )\n",
    "                    reward, done, info = env.step(letter)\n",
    "                    next_state = env.get_state_features()\n",
    "                    self.agent.update(state, letter, reward, next_state, done)\n",
    "                    episode_reward += reward\n",
    "                    \n",
    "                    # Track guess statistics\n",
    "                    if info['type'] == 'correct':\n",
    "                        episode_correct_guesses += 1\n",
    "                    elif info['type'] == 'wrong':\n",
    "                        episode_wrong_guesses += 1\n",
    "                        \n",
    "                    if env.won:\n",
    "                        episode_wins += 1\n",
    "                episode_games += 1\n",
    "            \n",
    "            self.agent.decay_epsilon()\n",
    "            \n",
    "            # Calculate metrics for this episode\n",
    "            win_rate = episode_wins / episode_games * 100 if episode_games > 0 else 0\n",
    "            avg_reward = episode_reward / episode_games if episode_games > 0 else 0\n",
    "            accuracy = episode_correct_guesses / (episode_correct_guesses + episode_wrong_guesses) * 100 if (episode_correct_guesses + episode_wrong_guesses) > 0 else 0\n",
    "            \n",
    "            episode_metrics.append({\n",
    "                'episode': episode + 1,\n",
    "                'win_rate': win_rate,\n",
    "                'avg_reward': avg_reward,\n",
    "                'accuracy': accuracy,\n",
    "                'epsilon': self.agent.epsilon\n",
    "            })\n",
    "            \n",
    "            # Print progress every 100 episodes\n",
    "            if (episode + 1) % 100 == 0 or (episode + 1) <= 10:\n",
    "                print(f\"Episode {episode+1:5d}: \"\n",
    "                      f\"Win Rate {win_rate:6.2f}% | \"\n",
    "                      f\"Avg Reward {avg_reward:7.1f} | \"\n",
    "                      f\"Accuracy {accuracy:6.2f}% | \"\n",
    "                      f\"Epsilon {self.agent.epsilon:.4f}\")\n",
    "            \n",
    "            # More detailed report every 500 episodes\n",
    "            if (episode + 1) % 500 == 0:\n",
    "                # Calculate rolling averages\n",
    "                recent_metrics = episode_metrics[-100:]  # Last 100 episodes\n",
    "                recent_win_rate = np.mean([m['win_rate'] for m in recent_metrics])\n",
    "                recent_accuracy = np.mean([m['accuracy'] for m in recent_metrics])\n",
    "                \n",
    "                print(\"-\" * 80)\n",
    "                print(f\"PROGRESS REPORT - Episode {episode+1}\")\n",
    "                print(f\"Recent Performance (last 100 episodes):\")\n",
    "                print(f\"  Average Win Rate: {recent_win_rate:.2f}%\")\n",
    "                print(f\"  Average Accuracy: {recent_accuracy:.2f}%\")\n",
    "                print(f\"  Current Epsilon:  {self.agent.epsilon:.4f}\")\n",
    "                print(\"-\" * 80)\n",
    "        \n",
    "        # Final training summary\n",
    "        print(\"=\"*80)\n",
    "        print(\"RL TRAINING COMPLETE!\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Calculate overall statistics\n",
    "        final_100_metrics = episode_metrics[-100:]\n",
    "        final_win_rate = np.mean([m['win_rate'] for m in final_100_metrics])\n",
    "        final_accuracy = np.mean([m['accuracy'] for m in final_100_metrics])\n",
    "        \n",
    "        print(f\"FINAL PERFORMANCE (last 100 episodes):\")\n",
    "        print(f\"  Win Rate:  {final_win_rate:.2f}%\")\n",
    "        print(f\"  Accuracy:  {final_accuracy:.2f}%\")\n",
    "        print(f\"  Epsilon:   {self.agent.epsilon:.4f}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self.agent, episode_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "025e66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== EVALUATOR ====================\n",
    "class FinalEvaluator:\n",
    "    def __init__(self, hmm_model, agent, test_words):\n",
    "        self.hmm = hmm_model\n",
    "        self.agent = agent\n",
    "        self.test_words = test_words\n",
    "        \n",
    "    def evaluate(self, num_games=None):\n",
    "        if num_games is None:\n",
    "            num_games = len(self.test_words)\n",
    "        \n",
    "        test_words = self.test_words[:num_games]\n",
    "        \n",
    "        wins = 0\n",
    "        total_wrong = 0\n",
    "        total_repeated = 0\n",
    "        total_guesses = 0\n",
    "        total_correct_guesses = 0\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"EVALUATING ON {num_games} TEST GAMES\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, word in enumerate(test_words):\n",
    "            env = HangmanEnvironment(word, self.hmm)\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                hmm_probs = self.hmm.predict_letter_probabilities(\n",
    "                    env.current_pattern,\n",
    "                    env.guessed_letters,\n",
    "                    env.lives_remaining\n",
    "                )\n",
    "                \n",
    "                letter = self.agent.select_action(\n",
    "                    env.current_pattern,\n",
    "                    env.guessed_letters,\n",
    "                    hmm_probs,\n",
    "                    env.lives_remaining,\n",
    "                    epsilon=0.0  # Greedy at test time\n",
    "                )\n",
    "                \n",
    "                reward, done, info = env.step(letter)\n",
    "                total_guesses += 1\n",
    "                \n",
    "                if info['type'] == 'wrong':\n",
    "                    total_wrong += 1\n",
    "                elif info['type'] == 'repeated':\n",
    "                    total_repeated += 1\n",
    "                elif info['type'] == 'correct':\n",
    "                    total_correct_guesses += 1\n",
    "            \n",
    "            if env.won:\n",
    "                wins += 1\n",
    "            \n",
    "            if (i + 1) % 500 == 0 or (i + 1) == num_games:\n",
    "                current_wr = (wins / (i + 1)) * 100\n",
    "                print(f\"  Progress: {i + 1:5d}/{num_games} | Win Rate: {current_wr:6.2f}%\")\n",
    "        \n",
    "        success_rate = wins / num_games\n",
    "        test_accuracy = total_correct_guesses / total_guesses * 100 if total_guesses > 0 else 0\n",
    "        final_score = wins - (total_wrong * 5) - (total_repeated * 2)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"FINAL TEST RESULTS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Total Games:          {num_games}\")\n",
    "        print(f\"Wins:                 {wins} ({wins/num_games*100:.2f}%)\")\n",
    "        print(f\"Losses:               {num_games - wins} ({(num_games-wins)/num_games*100:.2f}%)\")\n",
    "        print(f\"Total Guesses:        {total_guesses}\")\n",
    "        print(f\"Correct Guesses:      {total_correct_guesses} ({test_accuracy:.2f}% accuracy)\")\n",
    "        print(f\"Wrong Guesses:        {total_wrong} (avg: {total_wrong/num_games:.2f} per game)\")\n",
    "        print(f\"Repeated Guesses:     {total_repeated}\")\n",
    "        print(f\"\\nScore Breakdown:\")\n",
    "        print(f\"  Success Points:     +{wins}\")\n",
    "        print(f\"  Wrong Penalty:      -{total_wrong * 5}\")\n",
    "        print(f\"  Repeated Penalty:   -{total_repeated * 2}\")\n",
    "        print(f\"\\n  FINAL SCORE:        {final_score}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        return wins, total_wrong, total_repeated, final_score, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cecf007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== DEMO FUNCTION ====================\n",
    "def demo_agent_play(agent, hmm_model, words):\n",
    "    print(\"=\"*80)\n",
    "    print(\"HANGMAN RL AGENT STEP-BY-STEP DEMO\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for word in words:\n",
    "        print(f\"\\nStarting new game for word: '{word}'\")\n",
    "        env = HangmanEnvironment(word, hmm_model)\n",
    "        done = False\n",
    "        step_num = 1\n",
    "\n",
    "        # Header for each step\n",
    "        print(f\"{'Step':<6}{'Guess':<8}{'Pattern':<20}{'Lives Left':<12}{'Reward':<8}{'Game Status':<15}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        while not done:\n",
    "            # Obtain HMM probabilities to assist agent's guess\n",
    "            hmm_probs = hmm_model.predict_letter_probabilities(\n",
    "                env.current_pattern, env.guessed_letters, env.lives_remaining\n",
    "            )\n",
    "\n",
    "            # Agent chooses next letter (deterministic selection for demo)\n",
    "            letter = agent.select_action(\n",
    "                env.current_pattern, env.guessed_letters, hmm_probs, env.lives_remaining,\n",
    "                epsilon=0.0\n",
    "            )\n",
    "\n",
    "            # Perform a step in environment\n",
    "            reward, done, info = env.step(letter)\n",
    "\n",
    "            # Display the step details neatly\n",
    "            game_status = \"Won!\" if env.won else (\"Lost!\" if done else \"Ongoing\")\n",
    "            print(f\"{step_num:<6}{letter:<8}{env.current_pattern:<20}{env.lives_remaining:<12}{reward:<8.1f}{game_status:<15}\")\n",
    "\n",
    "            step_num += 1\n",
    "\n",
    "        print(f\"\\nGame complete for word '{word}': {'SUCCESS' if env.won else 'FAILURE'} in {step_num-1} steps\")\n",
    "        print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8375309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HANGMAN SOLVER: Statistical HMM + RL\n",
      "Reduced Training: 2,000 Episodes\n",
      "(Anti-overfitting design)\n",
      "================================================================================\n",
      "\n",
      "Loading existing HMM...\n",
      "\n",
      "Loading training data...\n",
      "\n",
      "Training RL agent for 2,000 episodes...\n",
      "================================================================================\n",
      "RL TRAINING 2000 EPISODES\n",
      "Words per episode: 100\n",
      "Total training games: 200,000\n",
      "================================================================================\n",
      "Episode     1: Win Rate  21.00% | Avg Reward   -68.4 | Accuracy  52.40% | Epsilon 0.1990\n",
      "Episode     2: Win Rate  26.00% | Avg Reward   -50.6 | Accuracy  54.39% | Epsilon 0.1980\n",
      "Episode     3: Win Rate  18.00% | Avg Reward   -73.0 | Accuracy  52.47% | Epsilon 0.1970\n",
      "Episode     4: Win Rate  24.00% | Avg Reward   -60.0 | Accuracy  53.61% | Epsilon 0.1960\n",
      "Episode     5: Win Rate  26.00% | Avg Reward   -51.7 | Accuracy  54.12% | Epsilon 0.1950\n",
      "Episode     6: Win Rate  22.00% | Avg Reward   -62.7 | Accuracy  53.04% | Epsilon 0.1941\n",
      "Episode     7: Win Rate  16.00% | Avg Reward   -75.3 | Accuracy  52.35% | Epsilon 0.1931\n",
      "Episode     8: Win Rate  23.00% | Avg Reward   -57.0 | Accuracy  54.19% | Epsilon 0.1921\n",
      "Episode     9: Win Rate  21.00% | Avg Reward   -63.9 | Accuracy  53.30% | Epsilon 0.1912\n",
      "Episode    10: Win Rate  22.00% | Avg Reward   -59.5 | Accuracy  54.12% | Epsilon 0.1902\n",
      "Episode   100: Win Rate  17.00% | Avg Reward   -84.6 | Accuracy  50.30% | Epsilon 0.1212\n",
      "Episode   200: Win Rate  24.00% | Avg Reward   -49.9 | Accuracy  55.03% | Epsilon 0.0734\n",
      "Episode   300: Win Rate  18.00% | Avg Reward   -73.7 | Accuracy  53.09% | Epsilon 0.0499\n",
      "Episode   400: Win Rate  33.00% | Avg Reward   -25.3 | Accuracy  56.61% | Epsilon 0.0499\n",
      "Episode   500: Win Rate  20.00% | Avg Reward   -67.3 | Accuracy  53.12% | Epsilon 0.0499\n",
      "--------------------------------------------------------------------------------\n",
      "PROGRESS REPORT - Episode 500\n",
      "Recent Performance (last 100 episodes):\n",
      "  Average Win Rate: 24.84%\n",
      "  Average Accuracy: 54.61%\n",
      "  Current Epsilon:  0.0499\n",
      "--------------------------------------------------------------------------------\n",
      "Episode   600: Win Rate  28.00% | Avg Reward   -45.5 | Accuracy  54.81% | Epsilon 0.0499\n",
      "Episode   700: Win Rate  24.00% | Avg Reward   -56.2 | Accuracy  53.82% | Epsilon 0.0499\n",
      "Episode   800: Win Rate  20.00% | Avg Reward   -63.8 | Accuracy  53.99% | Epsilon 0.0499\n",
      "Episode   900: Win Rate  20.00% | Avg Reward   -66.7 | Accuracy  53.23% | Epsilon 0.0499\n",
      "Episode  1000: Win Rate  22.00% | Avg Reward   -57.6 | Accuracy  54.48% | Epsilon 0.0499\n",
      "--------------------------------------------------------------------------------\n",
      "PROGRESS REPORT - Episode 1000\n",
      "Recent Performance (last 100 episodes):\n",
      "  Average Win Rate: 25.48%\n",
      "  Average Accuracy: 54.64%\n",
      "  Current Epsilon:  0.0499\n",
      "--------------------------------------------------------------------------------\n",
      "Episode  1100: Win Rate  20.00% | Avg Reward   -67.7 | Accuracy  52.51% | Epsilon 0.0499\n",
      "Episode  1200: Win Rate  21.00% | Avg Reward   -68.2 | Accuracy  52.53% | Epsilon 0.0499\n",
      "Episode  1300: Win Rate  24.00% | Avg Reward   -49.2 | Accuracy  55.79% | Epsilon 0.0499\n",
      "Episode  1400: Win Rate  33.00% | Avg Reward   -25.6 | Accuracy  57.54% | Epsilon 0.0499\n",
      "Episode  1500: Win Rate  30.00% | Avg Reward   -46.4 | Accuracy  53.48% | Epsilon 0.0499\n",
      "--------------------------------------------------------------------------------\n",
      "PROGRESS REPORT - Episode 1500\n",
      "Recent Performance (last 100 episodes):\n",
      "  Average Win Rate: 25.03%\n",
      "  Average Accuracy: 54.81%\n",
      "  Current Epsilon:  0.0499\n",
      "--------------------------------------------------------------------------------\n",
      "Episode  1600: Win Rate  28.00% | Avg Reward   -42.3 | Accuracy  55.83% | Epsilon 0.0499\n",
      "Episode  1700: Win Rate  20.00% | Avg Reward   -72.4 | Accuracy  52.38% | Epsilon 0.0499\n",
      "Episode  1800: Win Rate  19.00% | Avg Reward   -69.7 | Accuracy  53.24% | Epsilon 0.0499\n",
      "Episode  1900: Win Rate  27.00% | Avg Reward   -49.9 | Accuracy  54.39% | Epsilon 0.0499\n",
      "Episode  2000: Win Rate  24.00% | Avg Reward   -48.6 | Accuracy  56.45% | Epsilon 0.0499\n",
      "--------------------------------------------------------------------------------\n",
      "PROGRESS REPORT - Episode 2000\n",
      "Recent Performance (last 100 episodes):\n",
      "  Average Win Rate: 24.63%\n",
      "  Average Accuracy: 54.74%\n",
      "  Current Epsilon:  0.0499\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "RL TRAINING COMPLETE!\n",
      "================================================================================\n",
      "FINAL PERFORMANCE (last 100 episodes):\n",
      "  Win Rate:  24.63%\n",
      "  Accuracy:  54.74%\n",
      "  Epsilon:   0.0499\n",
      "================================================================================\n",
      "RL Agent saved to rl_agent_2000.pkl\n",
      "\n",
      "Loading test data...\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "EVALUATING ON 2000 TEST GAMES\n",
      "================================================================================\n",
      "  Progress:   500/2000 | Win Rate:  26.80%\n",
      "  Progress:  1000/2000 | Win Rate:  26.70%\n",
      "  Progress:  1500/2000 | Win Rate:  26.93%\n",
      "  Progress:  2000/2000 | Win Rate:  26.80%\n",
      "\n",
      "================================================================================\n",
      "FINAL TEST RESULTS\n",
      "================================================================================\n",
      "Total Games:          2000\n",
      "Wins:                 536 (26.80%)\n",
      "Losses:               1464 (73.20%)\n",
      "Total Guesses:        22936\n",
      "Correct Guesses:      11609 (50.61% accuracy)\n",
      "Wrong Guesses:        9327 (avg: 4.66 per game)\n",
      "Repeated Guesses:     0\n",
      "\n",
      "Score Breakdown:\n",
      "  Success Points:     +536\n",
      "  Wrong Penalty:      -46635\n",
      "  Repeated Penalty:   -0\n",
      "\n",
      "  FINAL SCORE:        -46099\n",
      "================================================================================\n",
      "\n",
      "Running demo with sample words...\n",
      "================================================================================\n",
      "HANGMAN RL AGENT STEP-BY-STEP DEMO\n",
      "================================================================================\n",
      "\n",
      "Starting new game for word: 'python'\n",
      "Step  Guess   Pattern             Lives Left  Reward  Game Status    \n",
      "--------------------------------------------------------------------------------\n",
      "1     e       ______              5           -13.0   Ongoing        \n",
      "2     a       ______              4           -16.0   Ongoing        \n",
      "3     i       ______              3           -19.0   Ongoing        \n",
      "4     n       _____n              3           12.0    Ongoing        \n",
      "5     o       ____on              3           12.0    Ongoing        \n",
      "6     r       ____on              2           -22.0   Ongoing        \n",
      "7     t       __t_on              2           12.0    Ongoing        \n",
      "8     s       __t_on              1           -25.0   Ongoing        \n",
      "9     c       __t_on              0           -100.0  Lost!          \n",
      "\n",
      "Game complete for word 'python': FAILURE in 9 steps\n",
      "================================================================================\n",
      "\n",
      "Starting new game for word: 'perfume'\n",
      "Step  Guess   Pattern             Lives Left  Reward  Game Status    \n",
      "--------------------------------------------------------------------------------\n",
      "1     e       _e____e             6           22.0    Ongoing        \n",
      "2     r       _er___e             6           12.0    Ongoing        \n",
      "3     t       _er___e             5           -13.0   Ongoing        \n",
      "4     n       _er___e             4           -16.0   Ongoing        \n",
      "5     l       _er___e             3           -19.0   Ongoing        \n",
      "6     a       _er___e             2           -22.0   Ongoing        \n",
      "7     i       _er___e             1           -25.0   Ongoing        \n",
      "8     s       _er___e             0           -100.0  Lost!          \n",
      "\n",
      "Game complete for word 'perfume': FAILURE in 8 steps\n",
      "================================================================================\n",
      "\n",
      "Starting new game for word: 'aditya'\n",
      "Step  Guess   Pattern             Lives Left  Reward  Game Status    \n",
      "--------------------------------------------------------------------------------\n",
      "1     e       ______              5           -13.0   Ongoing        \n",
      "2     a       a____a              5           22.0    Ongoing        \n",
      "3     r       a____a              4           -16.0   Ongoing        \n",
      "4     n       a____a              3           -19.0   Ongoing        \n",
      "5     l       a____a              2           -22.0   Ongoing        \n",
      "6     t       a__t_a              2           12.0    Ongoing        \n",
      "7     i       a_it_a              2           12.0    Ongoing        \n",
      "8     o       a_it_a              1           -25.0   Ongoing        \n",
      "9     s       a_it_a              0           -100.0  Lost!          \n",
      "\n",
      "Game complete for word 'aditya': FAILURE in 9 steps\n",
      "================================================================================\n",
      "\n",
      "Starting new game for word: 'hangman'\n",
      "Step  Guess   Pattern             Lives Left  Reward  Game Status    \n",
      "--------------------------------------------------------------------------------\n",
      "1     e       _______             5           -13.0   Ongoing        \n",
      "2     a       _a___a_             5           22.0    Ongoing        \n",
      "3     r       _a___a_             4           -16.0   Ongoing        \n",
      "4     l       _a___a_             3           -19.0   Ongoing        \n",
      "5     t       _a___a_             2           -22.0   Ongoing        \n",
      "6     n       _an__an             2           22.0    Ongoing        \n",
      "7     i       _an__an             1           -25.0   Ongoing        \n",
      "8     c       _an__an             0           -100.0  Lost!          \n",
      "\n",
      "Game complete for word 'hangman': FAILURE in 8 steps\n",
      "================================================================================\n",
      "\n",
      "Starting new game for word: 'challenge'\n",
      "Step  Guess   Pattern             Lives Left  Reward  Game Status    \n",
      "--------------------------------------------------------------------------------\n",
      "1     e       _____e__e           6           22.0    Ongoing        \n",
      "2     r       _____e__e           5           -13.0   Ongoing        \n",
      "3     n       _____en_e           5           12.0    Ongoing        \n",
      "4     t       _____en_e           4           -16.0   Ongoing        \n",
      "5     l       ___llen_e           4           22.0    Ongoing        \n",
      "6     a       __allen_e           4           12.0    Ongoing        \n",
      "7     i       __allen_e           3           -19.0   Ongoing        \n",
      "8     o       __allen_e           2           -22.0   Ongoing        \n",
      "9     c       c_allen_e           2           12.0    Ongoing        \n",
      "10    h       challen_e           2           12.0    Ongoing        \n",
      "11    s       challen_e           1           -25.0   Ongoing        \n",
      "12    d       challen_e           0           -100.0  Lost!          \n",
      "\n",
      "Game complete for word 'challenge': FAILURE in 12 steps\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TRAINING AND EVALUATION COMPLETE!\n",
      "================================================================================\n",
      "Training metrics saved to: training_metrics_2000.csv\n"
     ]
    }
   ],
   "source": [
    "# ==================== MAIN EXECUTION ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"HANGMAN SOLVER: Statistical HMM + RL\")\n",
    "    print(\"Reduced Training: 2,000 Episodes\")\n",
    "    print(\"(Anti-overfitting design)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Train HMM\n",
    "    try:\n",
    "        print(\"\\nLoading existing HMM...\")\n",
    "        hmm = StatisticalHangmanHMM.load_model('statistical_hmm.pkl')\n",
    "    except:\n",
    "        print(\"\\nTraining new HMM...\")\n",
    "        hmm = StatisticalHangmanHMM()\n",
    "        hmm.train('Data/Data/corpus.txt')\n",
    "        hmm.save_model('statistical_hmm.pkl')\n",
    "    \n",
    "    # Load corpus for training\n",
    "    print(\"\\nLoading training data...\")\n",
    "    with open('Data/Data/corpus.txt', 'r') as f:\n",
    "        corpus_words = [w.strip().lower() for w in f.readlines() if w.strip()]\n",
    "    \n",
    "    # Train RL agent with reduced episodes\n",
    "    print(f\"\\nTraining RL agent for 2,000 episodes...\")\n",
    "    trainer = RLTrainer(hmm, corpus_words)\n",
    "    agent, training_metrics = trainer.train(num_episodes=2000, words_per_episode=100)\n",
    "    agent.save_model('rl_agent_2000.pkl')\n",
    "    \n",
    "    # Load test set\n",
    "    print(\"\\nLoading test data...\")\n",
    "    with open('Data/Data/test.txt', 'r') as f:\n",
    "        test_words = [w.strip().lower() for w in f.readlines() if w.strip()]\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"\\nEvaluating on test set...\")\n",
    "    evaluator = FinalEvaluator(hmm, agent, test_words)\n",
    "    wins, wrong, repeated, score, accuracy = evaluator.evaluate()\n",
    "    \n",
    "    # Demo with sample words\n",
    "    print(f\"\\nRunning demo with sample words...\")\n",
    "    example_words = [\"python\", \"perfume\", \"aditya\", \"hangman\", \"challenge\"]\n",
    "    demo_agent_play(agent, hmm, example_words)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRAINING AND EVALUATION COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Save training metrics for analysis\n",
    "    metrics_df = pd.DataFrame(training_metrics)\n",
    "    metrics_df.to_csv('training_metrics_2000.csv', index=False)\n",
    "    print(f\"Training metrics saved to: training_metrics_2000.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
